# ğŸ§  Natron Transformer â€“ Multi-Task Financial Trading Model

**End-to-End GPU-Accelerated Deep Learning Pipeline for Financial Trading**

---

## ğŸ“‹ Overview

Natron Transformer is a state-of-the-art multi-task Transformer model designed for financial trading. It learns market structure through unsupervised pretraining and provides actionable predictions for:

- **Buy/Sell Classification** (Binary signals)
- **Direction Prediction** (Up/Down/Neutral)
- **Market Regime Classification** (6 regimes: Bull Strong/Weak, Range, Bear Weak/Strong, Volatile)

### ğŸ¯ Key Features

âœ… **~100 Technical Indicators** automatically extracted  
âœ… **Bias-Reduced Labeling** with institutional logic  
âœ… **Three-Phase Training**: Pretraining â†’ Supervised â†’ RL (optional)  
âœ… **GPU-Optimized** for PyTorch 2.x + CUDA  
âœ… **REST API** for real-time inference (<50ms latency)  
âœ… **MQL5 Integration Ready** for MetaTrader 5  

---

## ğŸ—ï¸ Architecture

```
Input (96 OHLCV candles)
    â†“
Feature Engine (~100 indicators)
    â†“
Transformer Encoder (6 layers, 8 heads, d_model=256)
    â†“
Multi-Task Heads:
    â”œâ”€ Buy Head (Sigmoid)
    â”œâ”€ Sell Head (Sigmoid)
    â”œâ”€ Direction Head (Softmax 3-class)
    â””â”€ Regime Head (Softmax 6-class)
```

### ğŸ“Š Feature Categories

| Category | Count | Examples |
|----------|-------|----------|
| Moving Averages | 13 | MA, EMA, slopes, crossovers |
| Momentum | 13 | RSI, MACD, CCI, Stochastic |
| Volatility | 15 | ATR, Bollinger Bands, Keltner |
| Volume | 9 | OBV, VWAP, MFI |
| Price Patterns | 8 | Doji, gaps, shadows |
| Returns | 8 | Log returns, cumulative |
| Trend Strength | 6 | ADX, Aroon, DI |
| Statistical | 6 | Skewness, Kurtosis, Hurst |
| Support/Resistance | 4 | Distance to highs/lows |
| Smart Money | 6 | Swing HL, BOS, CHoCH |
| Market Profile | 10 | POC, VAH, VAL, entropy |

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Installation

```bash
# Clone repository
git clone <your-repo>
cd natron-transformer

# Install dependencies
pip install -r requirements.txt

# Verify CUDA availability
python -c "import torch; print(torch.cuda.is_available())"
```

### 2ï¸âƒ£ Prepare Data

Place your OHLCV data in `data_export.csv` with columns:
```
time, open, high, low, close, volume
```

Or let the system generate synthetic data for testing.

### 3ï¸âƒ£ Train Model

**Full Pipeline (Recommended):**
```bash
python main.py --mode train
```

**Individual Phases:**
```bash
# Phase 1: Pretraining only
python main.py --mode pretrain

# Phase 2: Supervised training only
python main.py --mode supervised
```

### 4ï¸âƒ£ Start API Server

```bash
python main.py --mode api
```

Server runs at `http://localhost:5000`

### 5ï¸âƒ£ Test Inference

```bash
python main.py --mode test
```

---

## ğŸ”§ Configuration

Edit `config.yaml` to customize:

```yaml
# Model architecture
model:
  d_model: 256
  nhead: 8
  num_encoder_layers: 6
  dim_feedforward: 1024

# Training parameters
pretrain:
  epochs: 50
  batch_size: 128
  learning_rate: 0.0001

supervised:
  epochs: 100
  batch_size: 64
  learning_rate: 0.0001
  early_stopping_patience: 15
```

---

## ğŸ“¡ API Usage

### Endpoints

#### `POST /predict`

Send 96 OHLCV candles as JSON:

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "candles": [
      {"time": "2024-01-01 00:00", "open": 100.0, "high": 101.0, "low": 99.0, "close": 100.5, "volume": 1000},
      ...
    ]
  }'
```

**Response:**
```json
{
  "buy_prob": 0.71,
  "sell_prob": 0.24,
  "direction": "UP",
  "direction_probs": {
    "DOWN": 0.15,
    "UP": 0.69,
    "NEUTRAL": 0.16
  },
  "regime": "BULL_WEAK",
  "regime_probs": {
    "BULL_STRONG": 0.12,
    "BULL_WEAK": 0.45,
    "RANGE": 0.18,
    "BEAR_WEAK": 0.10,
    "BEAR_STRONG": 0.05,
    "VOLATILE": 0.10
  },
  "confidence": 0.82
}
```

#### `GET /health`

Health check endpoint.

#### `GET /info`

Returns model architecture information.

---

## ğŸ“ Training Pipeline Details

### Phase 1: Unsupervised Pretraining

**Objective:** Learn latent market structure

**Methods:**
- Masked Token Reconstruction (15% masking)
- Contrastive Learning (InfoNCE)

**Duration:** ~50 epochs

**Output:** Pretrained encoder weights

### Phase 2: Supervised Fine-Tuning

**Objective:** Predict Buy/Sell/Direction/Regime

**Loss Function:**
```
L_total = w_buyÂ·L_buy + w_sellÂ·L_sell + w_dirÂ·L_direction + w_regÂ·L_regime
```

**Metrics:**
- Buy/Sell Accuracy
- Direction Accuracy (3-class)
- Regime Accuracy (6-class)

**Duration:** ~100 epochs with early stopping

### Phase 3: Reinforcement Learning (Optional)

**Objective:** Optimize trading performance

**Algorithm:** PPO or SAC

**Reward:**
```
R = profit - Î±Â·turnover - Î²Â·drawdown
```

**Status:** Placeholder (requires trading environment)

---

## ğŸ“Š Label Generation V2

### Buy Signal (â‰¥2 conditions)
1. close > MA20 > MA50
2. RSI > 50 or crossed up from <30
3. close > BB mid and MA20 slope > 0
4. volume > 1.5Ã— rolling20
5. position_in_range â‰¥ 0.7
6. MACD_hist > 0 and rising

### Sell Signal (â‰¥2 conditions)
1. close < MA20 < MA50
2. RSI < 50 or turned down from >70
3. close < BB mid and MA20 slope < 0
4. volume > 1.5Ã— rolling20 and position â‰¤ 0.3
5. MACD_hist < 0 and falling
6. minus_DI > plus_DI

### Direction (3-class)
- **UP**: future_close > current + buffer
- **DOWN**: future_close < current - buffer
- **NEUTRAL**: otherwise

### Regime Classification (6 states)
| ID | Regime | Condition |
|----|--------|-----------|
| 0 | BULL_STRONG | trend > +2%, ADX > 25 |
| 1 | BULL_WEAK | 0 < trend â‰¤ +2% |
| 2 | RANGE | Lateral market (default) |
| 3 | BEAR_WEAK | -2% â‰¤ trend < 0 |
| 4 | BEAR_STRONG | trend < -2%, ADX > 25 |
| 5 | VOLATILE | ATR > 90th percentile |

---

## ğŸ”Œ MQL5 Integration

### Architecture

```
MetaTrader 5 (MQL5 EA)
    â†“ Socket
Python Socket Server
    â†“ REST API
Natron Transformer (GPU)
```

### Example Integration (Coming Soon)

See `examples/mql5_integration.mq5` for MetaTrader 5 Expert Advisor template.

---

## ğŸ“ Project Structure

```
natron-transformer/
â”œâ”€â”€ main.py                 # Main orchestration script
â”œâ”€â”€ config.yaml             # Configuration file
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_engine.py  # Feature extraction (~100 indicators)
â”‚   â”œâ”€â”€ label_generator.py # Label generation V2
â”‚   â”œâ”€â”€ dataset.py         # PyTorch datasets
â”‚   â”œâ”€â”€ model.py           # Transformer architecture
â”‚   â”œâ”€â”€ train.py           # Training loops (3 phases)
â”‚   â””â”€â”€ api.py             # Flask inference API
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data_export.csv    # Input OHLCV data
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ natron_v2.pt       # Trained model
â”‚   â””â”€â”€ scaler.pkl         # Feature scaler
â””â”€â”€ logs/                  # TensorBoard logs
```

---

## ğŸ§ª Testing Individual Modules

### Test Feature Engine
```bash
python src/feature_engine.py
```

### Test Label Generator
```bash
python src/label_generator.py
```

### Test Dataset
```bash
python src/dataset.py
```

### Test Model
```bash
python src/model.py
```

---

## ğŸ“ˆ Monitoring Training

Use TensorBoard to monitor training:

```bash
tensorboard --logdir logs/
```

Navigate to `http://localhost:6006`

---

## ğŸ”¬ Research & Development

### Natron Philosophy

> "Natron doesn't just predict Buy/Sell â€” it learns the grammar of the market."

**Three-Stage Learning:**
1. **Structure Understanding** (Pretrain) - Temporal dependencies
2. **Signal Recognition** (Supervised) - Trade setups
3. **Behavioral Adaptation** (RL) - Real-world optimization

---

## âš™ï¸ System Requirements

### Minimum
- Python 3.10+
- 8GB RAM
- CPU with AVX2 support

### Recommended
- Python 3.10+
- 16GB+ RAM
- NVIDIA GPU with 8GB+ VRAM
- CUDA 11.8+
- Ubuntu 20.04+ / Debian 11+

---

## ğŸ› Troubleshooting

### CUDA Out of Memory
Reduce batch size in `config.yaml`:
```yaml
supervised:
  batch_size: 32  # Reduce from 64
```

### Model Not Found
Ensure training completed successfully and check:
```bash
ls -lh model/natron_v2.pt
```

### API Connection Error
Verify server is running:
```bash
curl http://localhost:5000/health
```

---

## ğŸ“š References

- Vaswani et al. (2017) - Attention Is All You Need
- Devlin et al. (2018) - BERT: Pre-training of Deep Bidirectional Transformers
- Schulman et al. (2017) - Proximal Policy Optimization

---

## ğŸ“œ License

MIT License - See LICENSE file for details

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ğŸ“§ Contact

For questions, issues, or collaboration:
- Open an issue on GitHub
- Email: [Your contact]

---

## ğŸ‰ Acknowledgments

Built with:
- PyTorch 2.x
- Transformers
- Pandas, NumPy, Scikit-learn
- Flask
- TensorBoard

---

**Natron Transformer V2** - *Institutional-Grade AI for Financial Trading*

*"Where Deep Learning Meets Market Microstructure"*
